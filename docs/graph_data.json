{
  "nodes": [
    {
      "id": "2601.04107v1",
      "name": "From Abstract Threats to Institutional Realities: A Comparative Semantic Network Analysis of AI Securitisation in the US, EU, and China",
      "group": "paper",
      "val": 30,
      "abstract": "Artificial intelligence governance exhibits a striking paradox: while major jurisdictions converge rhetorically around concepts such as safety, risk, and accountability, their regulatory frameworks remain fundamentally divergent and mutually unintelligible. This paper argues that this fragmentation cannot be explained solely by geopolitical rivalry, institutional complexity, or instrument selection. Instead, it stems from how AI is constituted as an object of governance through distinct institutional logics. Integrating securitisation theory with the concept of the dispositif, we demonstrate that jurisdictions govern ontologically different objects under the same vocabulary. Using semantic network analysis of official policy texts from the European Union, the United States, and China (2023-2025), we trace how concepts like safety are embedded within divergent semantic architectures. Our findings reveal that the EU juridifies AI as a certifiable product through legal-bureaucratic logic; the US operationalises AI as an optimisable system through market-liberal logic; and China governs AI as socio-technical infrastructure through holistic state logic. We introduce the concept of structural incommensurability to describe this condition of ontological divergence masked by terminological convergence. This reframing challenges ethics-by-principles approaches to global AI governance, suggesting that coordination failures arise not from disagreement over values but from the absence of a shared reference object.",
      "url": "https://arxiv.org/pdf/2601.04107v1",
      "date": "2026-01-07T17:12:03+00:00"
    },
    {
      "id": "auth_ruiyi_guo",
      "name": "Ruiyi Guo",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_bodong_zhang",
      "name": "Bodong Zhang",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_institutional_logics",
      "name": "institutional logics",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_governance",
      "name": "ai governance",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_governs_ai",
      "name": "governs ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_intelligence_governance",
      "name": "intelligence governance",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_govern_ontologically",
      "name": "govern ontologically",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.04094v1",
      "name": "The Bathtub of European AI Governance: Identifying Technical Sandboxes as the Micro-Foundation of Regulatory Learning",
      "group": "paper",
      "val": 30,
      "abstract": "The EU AI Act adopts a horizontal and adaptive approach to govern AI technologies characterised by rapid development and unpredictable emerging capabilities. To maintain relevance, the Act embeds provisions for regulatory learning. However, these provisions operate within a complex network of actors and mechanisms that lack a clearly defined technical basis for scalable information flow. This paper addresses this gap by establishing a theoretical model of regulatory learning space defined by the AI Act, decomposed into micro, meso, and macro levels. Drawing from this functional perspective of this model, we situate the diverse stakeholders - ranging from the EU Commission at the macro level to AI developers at the micro level - within the transitions of enforcement (macro-micro) and evidence aggregation (micro-macro). We identify AI Technical Sandboxes as the essential engine for evidence generation at the micro level, providing the necessary data to drive scalable learning across all levels of the model. By providing an extensive discussion of the requirements and challenges for AITSes to serve as this micro-level evidence generator, we aim to bridge the gap between legislative commands and technical operationalisation, thereby enabling a structured discourse between technical and legal experts.",
      "url": "https://arxiv.org/pdf/2601.04094v1",
      "date": "2026-01-07T17:01:06+00:00"
    },
    {
      "id": "auth_tom_deckenbrunnen",
      "name": "Tom Deckenbrunnen",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_alessio_buscemi",
      "name": "Alessio Buscemi",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_marco_almada",
      "name": "Marco Almada",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_alfredo_capozucca",
      "name": "Alfredo Capozucca",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_german_castignani",
      "name": "German Castignani",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_eu_ai",
      "name": "eu ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_act",
      "name": "ai act",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_enforcement_macro",
      "name": "enforcement macro",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_govern_ai",
      "name": "govern ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_technical",
      "name": "ai technical",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03788v1",
      "name": "Criminal Liability of Generative Artificial Intelligence Providers for User-Generated Child Sexual Abuse Material",
      "group": "paper",
      "val": 30,
      "abstract": "The development of more powerful Generative Artificial Intelligence (GenAI) has expanded its capabilities and the variety of outputs. This has introduced significant legal challenges, including gray areas in various legal systems, such as the assessment of criminal liability for those responsible for these models. Therefore, we conducted a multidisciplinary study utilizing the statutory interpretation of relevant German laws, which, in conjunction with scenarios, provides a perspective on the different properties of GenAI in the context of Child Sexual Abuse Material (CSAM) generation. We found that generating CSAM with GenAI may have criminal and legal consequences not only for the user committing the primary offense but also for individuals responsible for the models, such as independent software developers, researchers, and company representatives. Additionally, the assessment of criminal liability may be affected by contextual and technical factors, including the type of generated image, content moderation policies, and the model's intended purpose. Based on our findings, we discussed the implications for different roles, as well as the requirements when developing such systems.",
      "url": "https://arxiv.org/pdf/2601.03788v1",
      "date": "2026-01-07T10:38:35+00:00"
    },
    {
      "id": "auth_anamaria_mojica_hanke",
      "name": "Anamaria Mojica-Hanke",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_thomas_goger",
      "name": "Thomas Goger",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_svenja_wölfel",
      "name": "Svenja Wölfel",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_brian_valerius",
      "name": "Brian Valerius",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_steffen_herbold",
      "name": "Steffen Herbold",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_offense_individuals",
      "name": "offense individuals",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_criminal_liability",
      "name": "criminal liability",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_legal_consequences",
      "name": "legal consequences",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_criminal_legal",
      "name": "criminal legal",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_legal_systems",
      "name": "legal systems",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03733v1",
      "name": "RadDiff: Describing Differences in Radiology Image Sets with Natural Language",
      "group": "paper",
      "val": 30,
      "abstract": "Understanding how two radiology image sets differ is critical for generating clinical insights and for interpreting medical AI systems. We introduce RadDiff, a multimodal agentic system that performs radiologist-style comparative reasoning to describe clinically meaningful differences between paired radiology studies. RadDiff builds on a proposer-ranker framework from VisDiff, and incorporates four innovations inspired by real diagnostic workflows: (1) medical knowledge injection through domain-adapted vision-language models; (2) multimodal reasoning that integrates images with their clinical reports; (3) iterative hypothesis refinement across multiple reasoning rounds; and (4) targeted visual search that localizes and zooms in on salient regions to capture subtle findings. To evaluate RadDiff, we construct RadDiffBench, a challenging benchmark comprising 57 expert-validated radiology study pairs with ground-truth difference descriptions. On RadDiffBench, RadDiff achieves 47% accuracy, and 50% accuracy when guided by ground-truth reports, significantly outperforming the general-domain VisDiff baseline. We further demonstrate RadDiff's versatility across diverse clinical tasks, including COVID-19 phenotype comparison, racial subgroup analysis, and discovery of survival-related imaging features. Together, RadDiff and RadDiffBench provide the first method-and-benchmark foundation for systematically uncovering meaningful differences in radiological data.",
      "url": "https://arxiv.org/pdf/2601.03733v1",
      "date": "2026-01-07T09:25:04+00:00"
    },
    {
      "id": "auth_xiaoxian_shen",
      "name": "Xiaoxian Shen",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_yuhui_zhang",
      "name": "Yuhui Zhang",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_sahithi_ankireddy",
      "name": "Sahithi Ankireddy",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_xiaohan_wang",
      "name": "Xiaohan Wang",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_maya_varma",
      "name": "Maya Varma",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_henry_guo",
      "name": "Henry Guo",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_curtis_langlotz",
      "name": "Curtis Langlotz",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_serena_yeung_levy",
      "name": "Serena Yeung-Levy",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_multimodal_reasoning",
      "name": "multimodal reasoning",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_medical_ai",
      "name": "medical ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_radiology_image",
      "name": "radiology image",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_understanding_radiology",
      "name": "understanding radiology",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_raddiff_multimodal",
      "name": "raddiff multimodal",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03709v1",
      "name": "The Power of 10: New Rules for the Digital World",
      "group": "paper",
      "val": 30,
      "abstract": "As artificial intelligence rapidly advances, society is increasingly captivated by promises of superhuman machines and seamless digital futures. Yet these visions often obscure mounting social, ethical, and psychological concerns tied to pervasive digital technologies - from surveillance to mental health crises. This article argues that a guiding ethos is urgently needed to navigate these transformations. Inspired by the lasting influence of the biblical Ten Commandments, a European interdisciplinary group has proposed \"Ten Rules for the Digital World\" - a novel ethical framework to help individuals and societies make prudent, human-centered decisions in the age of \"supercharged\" technology.",
      "url": "https://arxiv.org/pdf/2601.03709v1",
      "date": "2026-01-07T08:49:02+00:00"
    },
    {
      "id": "auth_sarah_spiekermann_hoff",
      "name": "Sarah Spiekermann-Hoff",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_marc_langheinrich",
      "name": "Marc Langheinrich",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_johannes_hoff",
      "name": "Johannes Hoff",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_christiane_wendehorst",
      "name": "Christiane Wendehorst",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_jürgen_pfeffer",
      "name": "Jürgen Pfeffer",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_thomas_fuchs",
      "name": "Thomas Fuchs",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_armin_grunwald",
      "name": "Armin Grunwald",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_digital_world",
      "name": "digital world",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_digital_technologies",
      "name": "digital technologies",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ethical_psychological",
      "name": "ethical psychological",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_rules_digital",
      "name": "rules digital",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_digital",
      "name": "digital",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03693v1",
      "name": "Can AI Chatbots Provide Coaching in Engineering? Beyond Information Processing Toward Mastery",
      "group": "paper",
      "val": 30,
      "abstract": "Engineering education faces a double disruption: traditional apprenticeship models that cultivated judgment and tacit skill are eroding, just as generative AI emerges as an informal coaching partner. This convergence rekindles long-standing questions in the philosophy of AI and cognition about the limits of computation, the nature of embodied rationality, and the distinction between information processing and wisdom. Building on this rich intellectual tradition, this paper examines whether AI chatbots can provide coaching that fosters mastery rather than merely delivering information. We synthesize critical perspectives from decades of scholarship on expertise, tacit knowledge, and human-machine interaction, situating them within the context of contemporary AI-driven education. Empirically, we report findings from a mixed-methods study (N = 75 students, N = 7 faculty) exploring the use of a coaching chatbot in engineering education. Results reveal a consistent boundary: participants accept AI for technical problem solving (convergent tasks; M = 3.84 on a 1-5 Likert scale) but remain skeptical of its capacity for moral, emotional, and contextual judgment (divergent tasks). Faculty express stronger concerns over risk (M = 4.71 vs. M = 4.14, p = 0.003), and privacy emerges as a key requirement, with 64-71 percent of participants demanding strict confidentiality. Our findings suggest that while generative AI can democratize access to cognitive and procedural support, it cannot replicate the embodied, value-laden dimensions of human mentorship. We propose a multiplex coaching framework that integrates human wisdom within expert-in-the-loop models, preserving the depth of apprenticeship while leveraging AI scalability to enrich the next generation of engineering education.",
      "url": "https://arxiv.org/pdf/2601.03693v1",
      "date": "2026-01-07T08:28:47+00:00"
    },
    {
      "id": "auth_junaid_qadir",
      "name": "Junaid Qadir",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_muhammad_adil_attique",
      "name": "Muhammad Adil Attique",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_saleha_shoaib",
      "name": "Saleha Shoaib",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_syed_ibrahim_ghaznavi",
      "name": "Syed Ibrahim Ghaznavi",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_examines_ai",
      "name": "examines ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_coaching_chatbot",
      "name": "coaching chatbot",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_intellectual",
      "name": "intellectual",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_chatbots",
      "name": "ai chatbots",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03547v1",
      "name": "Governance of Technological Transition: A Predator-Prey Analysis of AI Capital in China's Economy and Its Policy Implications",
      "group": "paper",
      "val": 30,
      "abstract": "The rapid integration of Artificial Intelligence (AI) into China's economy presents a classic governance challenge: how to harness its growth potential while managing its disruptive effects on traditional capital and labor markets. This study addresses this policy dilemma by modeling the dynamic interactions between AI capital, physical capital, and labor within a Lotka-Volterra predator-prey framework. Using annual Chinese data (2016-2023), we quantify the interaction strengths, identify stable equilibria, and perform a global sensitivity analysis. Our results reveal a consistent pattern where AI capital acts as the 'prey', stimulating both physical capital accumulation and labor compensation (wage bill), while facing only weak constraining feedback. The equilibrium points are stable nodes, indicating a policy-mediated convergence path rather than volatile cycles. Critically, the sensitivity analysis shows that the labor market equilibrium is overwhelmingly driven by AI-related parameters, whereas the physical capital equilibrium is also influenced by its own saturation dynamics. These findings provide a systemic, quantitative basis for policymakers: (1) to calibrate AI promotion policies by recognizing the asymmetric leverage points in capital vs. labor markets; (2) to anticipate and mitigate structural rigidities that may arise from current regulatory settings; and (3) to prioritize interventions that foster complementary growth between AI and traditional economic structures while ensuring broad-base distribution of technological gains.",
      "url": "https://arxiv.org/pdf/2601.03547v1",
      "date": "2026-01-07T03:30:46+00:00"
    },
    {
      "id": "auth_kunpeng_wang",
      "name": "Kunpeng Wang",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_jiahui_hu",
      "name": "Jiahui Hu",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_ai_china",
      "name": "ai china",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_capital",
      "name": "ai capital",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_china_economy",
      "name": "china economy",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_growth_ai",
      "name": "growth ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_capital_equilibrium",
      "name": "capital equilibrium",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03469v1",
      "name": "Content vs. Form: What Drives the Writing Score Gap Across Socioeconomic Backgrounds? A Generated Panel Approach",
      "group": "paper",
      "val": 30,
      "abstract": "Students from different socioeconomic backgrounds exhibit persistent gaps in test scores, gaps that can translate into unequal educational and labor-market outcomes later in life. In many assessments, performance reflects not only what students know, but also how effectively they can communicate that knowledge. This distinction is especially salient in writing assessments, where scores jointly reward the substance of students' ideas and the way those ideas are expressed. As a result, observed score gaps may conflate differences in underlying content with differences in expressive skill. A central question, therefore, is how much of the socioeconomic-status (SES) gap in scores is driven by differences in what students say versus how they say it. We study this question using a large corpus of persuasive essays written by U.S. middle- and high-school students. We introduce a new measurement strategy that separates content from style by leveraging large language models to generate multiple stylistic variants of each essay. These rewrites preserve the underlying arguments while systematically altering surface expression, creating a \"generated panel\" that introduces controlled within-essay variation in style. This approach allows us to decompose SES gaps in writing scores into contributions from content and style. We find an SES gap of 0.67 points on a 1-6 scale. Approximately 69% of the gap is attributable to differences in essay content quality, Style differences account for 26% of the gap, and differences in evaluation standards across SES groups account for the remaining 5%. These patterns seems stable across demographic subgroups and writing tasks. More broadly, our approach shows how large language models can be used to generate controlled variation in observational data, enabling researchers to isolate and quantify the contributions of otherwise entangled factors.",
      "url": "https://arxiv.org/pdf/2601.03469v1",
      "date": "2026-01-06T23:45:18+00:00"
    },
    {
      "id": "auth_nadav_kunievsky",
      "name": "Nadav Kunievsky",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_pedro_pertusi",
      "name": "Pedro Pertusi",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_essay_variation",
      "name": "essay variation",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_essay_rewrites",
      "name": "essay rewrites",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_persuasive_essays",
      "name": "persuasive essays",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_writing_scores",
      "name": "writing scores",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_essay_content",
      "name": "essay content",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03458v1",
      "name": "Automated Feedback Generation for Undergraduate Mathematics: Development and Evaluation of an AI Teaching Assistant",
      "group": "paper",
      "val": 30,
      "abstract": "Intelligent tutoring systems have long enabled automated immediate feedback on student work when it is presented in a tightly structured format and when problems are very constrained, but reliably assessing free-form mathematical reasoning remains challenging.   We present a system that processes free-form natural language input, handles a wide range of edge cases, and comments competently not only on the technical correctness of submitted proofs, but also on style and presentation issues. We discuss the advantages and disadvantages of various approaches to the evaluation of such a system, and show that by the metrics we evaluate, the quality of the feedback generated is comparable to that produced by human experts when assessing early undergraduate homework. We stress-test our system with a small set of more advanced and unusual questions, and report both significant gaps and encouraging successes in that more challenging setting.   Our system uses large language models in a modular workflow. The workflow configuration is human-readable and editable without programming knowledge, and allows some intermediate steps to be precomputed or injected by the instructor.   A version of our tool is deployed on the Imperial mathematics homework platform Lambdafeedback. We report also on the integration of our tool into this platform.",
      "url": "https://arxiv.org/pdf/2601.03458v1",
      "date": "2026-01-06T23:02:22+00:00"
    },
    {
      "id": "auth_aron_gohr",
      "name": "Aron Gohr",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_marie_amelie_lawn",
      "name": "Marie-Amelie Lawn",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_kevin_gao",
      "name": "Kevin Gao",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_inigo_serjeant",
      "name": "Inigo Serjeant",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_stephen_heslip",
      "name": "Stephen Heslip",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_tutoring_systems",
      "name": "tutoring systems",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_intelligent_tutoring",
      "name": "intelligent tutoring",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_tutoring",
      "name": "tutoring",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_homework_platform",
      "name": "homework platform",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_editable_programming",
      "name": "editable programming",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03430v1",
      "name": "An Empirical Analysis of Community and Coding Patterns in OSS4SG vs. Conventional OSS",
      "group": "paper",
      "val": 30,
      "abstract": "Open Source Software for Social Good (OSS4SG) projects aim to address critical societal challenges, such as healthcare access and community safety. Understanding the community dynamics and contributor patterns in these projects is essential for ensuring their sustainability and long-term impact. However, while extensive research has focused on conventional Open Source Software (OSS), little is known about how the mission-driven nature of OSS4SG influences its development practices. To address this gap, we conduct a large-scale empirical study of 1,039 GitHub repositories, comprising 422 OSS4SG and 617 conventional OSS projects, to compare community structure, contributor engagement, and coding practices. Our findings reveal that OSS4SG projects foster significantly more stable and \"sticky\" (63.4%) communities, whereas conventional OSS projects are more \"magnetic\" (75.4%), attracting a high turnover of contributors. OSS4SG projects also demonstrate consistent engagement throughout the year, while conventional OSS communities exhibit seasonal fluctuations. Additionally, OSS4SG projects rely heavily on core contributors for both code quality and issue resolution, while conventional OSS projects leverage casual contributors for issue resolution, with core contributors focusing primarily on code quality.",
      "url": "https://arxiv.org/pdf/2601.03430v1",
      "date": "2026-01-06T21:37:12+00:00"
    },
    {
      "id": "auth_mohamed_ouf",
      "name": "Mohamed Ouf",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_shayan_noei",
      "name": "Shayan Noei",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_zeph_van_iterson",
      "name": "Zeph Van Iterson",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_mariam_guizani",
      "name": "Mariam Guizani",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_ying_zou",
      "name": "Ying Zou",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_contributors_oss4sg",
      "name": "contributors oss4sg",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_contributors_code",
      "name": "contributors code",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_github",
      "name": "github",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_oss_communities",
      "name": "oss communities",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_oss_projects",
      "name": "oss projects",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.03222v1",
      "name": "The Fake Friend Dilemma: Trust and the Political Economy of Conversational AI",
      "group": "paper",
      "val": 30,
      "abstract": "As conversational AI systems become increasingly integrated into everyday life, they raise pressing concerns about user autonomy, trust, and the commercial interests that influence their behavior. To address these concerns, this paper develops the Fake Friend Dilemma (FFD), a sociotechnical condition in which users place trust in AI agents that appear supportive while pursuing goals that are misaligned with the user's own. The FFD provides a critical framework for examining how anthropomorphic AI systems facilitate subtle forms of manipulation and exploitation. Drawing on literature in trust, AI alignment, and surveillance capitalism, we construct a typology of harms, including covert advertising, political propaganda, behavioral nudging, and surveillance. We then assess possible mitigation strategies, including both structural and technical interventions. By focusing on trust as a vector of asymmetrical power, the FFD offers a lens for understanding how AI systems may undermine user autonomy while maintaining the appearance of helpfulness.",
      "url": "https://arxiv.org/pdf/2601.03222v1",
      "date": "2026-01-06T18:07:52+00:00"
    },
    {
      "id": "auth_jacob_erickson",
      "name": "Jacob Erickson",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_trust_ai",
      "name": "trust ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_autonomy_trust",
      "name": "autonomy trust",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_conversational_ai",
      "name": "conversational ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_agents",
      "name": "ai agents",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_focusing_trust",
      "name": "focusing trust",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.04175v1",
      "name": "Legal Alignment for Safe and Ethical AI",
      "group": "paper",
      "val": 30,
      "abstract": "Alignment of artificial intelligence (AI) encompasses the normative problem of specifying how AI systems should act and the technical problem of ensuring AI systems comply with those specifications. To date, AI alignment has generally overlooked an important source of knowledge and practice for grappling with these problems: law. In this paper, we aim to fill this gap by exploring how legal rules, principles, and methods can be leveraged to address problems of alignment and inform the design of AI systems that operate safely and ethically. This emerging field -- legal alignment -- focuses on three research directions: (1) designing AI systems to comply with the content of legal rules developed through legitimate institutions and processes, (2) adapting methods from legal interpretation to guide how AI systems reason and make decisions, and (3) harnessing legal concepts as a structural blueprint for confronting challenges of reliability, trust, and cooperation in AI systems. These research directions present new conceptual, empirical, and institutional questions, which include examining the specific set of laws that particular AI systems should follow, creating evaluations to assess their legal compliance in real-world settings, and developing governance frameworks to support the implementation of legal alignment in practice. Tackling these questions requires expertise across law, computer science, and other disciplines, offering these communities the opportunity to collaborate in designing AI for the better.",
      "url": "https://arxiv.org/pdf/2601.04175v1",
      "date": "2026-01-07T18:42:04+00:00"
    },
    {
      "id": "auth_noam_kolt",
      "name": "Noam Kolt",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_nicholas_caputo",
      "name": "Nicholas Caputo",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_jack_boeglin",
      "name": "Jack Boeglin",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_cullen_o'keefe",
      "name": "Cullen O'Keefe",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_rishi_bommasani",
      "name": "Rishi Bommasani",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_stephen_casper",
      "name": "Stephen Casper",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_mariano_florentino_cuéllar",
      "name": "Mariano-Florentino Cuéllar",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_noah_feldman",
      "name": "Noah Feldman",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_iason_gabriel",
      "name": "Iason Gabriel",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_gillian_k_hadfield",
      "name": "Gillian K. Hadfield",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_lewis_hammond",
      "name": "Lewis Hammond",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_peter_henderson",
      "name": "Peter Henderson",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_atoosa_kasirzadeh",
      "name": "Atoosa Kasirzadeh",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_seth_lazar",
      "name": "Seth Lazar",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_anka_reuel",
      "name": "Anka Reuel",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_kevin_l_wei",
      "name": "Kevin L. Wei",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_jonathan_zittrain",
      "name": "Jonathan Zittrain",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_legal_alignment",
      "name": "legal alignment",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_legal_compliance",
      "name": "legal compliance",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_exploring_legal",
      "name": "exploring legal",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_specifying_ai",
      "name": "specifying ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ensuring_ai",
      "name": "ensuring ai",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.05232v1",
      "name": "Measuring and Fostering Peace through Machine Learning and Artificial Intelligence",
      "group": "paper",
      "val": 30,
      "abstract": "We used machine learning and artificial intelligence: 1) to measure levels of peace in countries from news and social media and 2) to develop on-line tools that promote peace by helping users better understand their own media diet. For news media, we used neural networks to measure levels of peace from text embeddings of on-line news sources. The model, trained on one news media dataset also showed high accuracy when used to analyze a different news dataset. For social media, such as YouTube, we developed other models to measure levels of social dimensions important in peace using word level (GoEmotions) and context level (Large Language Model) methods. To promote peace, we note that 71% of people 20-40 years old daily view most of their news through short videos on social media. Content creators of these videos are biased towards creating videos with emotional activation, making you angry to engage you, to increase clicks. We developed and tested a Chrome extension, MirrorMirror, which provides real-time feedback to YouTube viewers about the peacefulness of the media they are watching. Our long term goal is for MirrorMirror to evolve into an open-source tool for content creators, journalists, researchers, platforms, and individual users to better understand the tone of their media creation and consumption and its effects on viewers. Moving beyond simple engagement metrics, we hope to encourage more respectful, nuanced, and informative communication.",
      "url": "https://arxiv.org/pdf/2601.05232v1",
      "date": "2026-01-08T18:57:01+00:00"
    },
    {
      "id": "auth_p_gilda",
      "name": "P. Gilda",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_p_dungarwal",
      "name": "P. Dungarwal",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_a_thongkham",
      "name": "A. Thongkham",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_e_t_ajayi",
      "name": "E. T. Ajayi",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_s_choudhary",
      "name": "S. Choudhary",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_t_m_terol",
      "name": "T. M. Terol",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_c_lam",
      "name": "C. Lam",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_j_p_araujo",
      "name": "J. P. Araujo",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_m_mcfadyen_mungalln",
      "name": "M. McFadyen-Mungalln",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_l_s_liebovitch",
      "name": "L. S. Liebovitch",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_p_t_coleman",
      "name": "P. T. Coleman",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_h_west",
      "name": "H. West",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_k_sieck",
      "name": "K. Sieck",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_s_carter",
      "name": "S. Carter",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_news_social",
      "name": "news social",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_social_media",
      "name": "social media",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_news_dataset",
      "name": "news dataset",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_videos_social",
      "name": "videos social",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_media_youtube",
      "name": "media youtube",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.04958v1",
      "name": "The unsuitability of existing regulations to reach sustainable AI",
      "group": "paper",
      "val": 30,
      "abstract": "This paper examines the European Union's emerging regulatory landscape - focusing on the AI Act, corporate sustainability reporting and due diligence regimes (CSRD and CSDDD), and data center regulation - to assess whether it can effectively govern AI's environmental footprint. We argue that, despite incremental progress, current approaches remain ill-suited to correcting the market failures underpinning AI-related energy use, water consumption, and material demand. Key shortcomings include narrow disclosure requirements, excessive reliance on voluntary standards, weak enforcement mechanisms, and a structural disconnect between AI-specific impacts and broader sustainability laws. The analysis situates these regulatory gaps within a wider ecosystem of academic research, civil society advocacy, standard-setting, and industry initiatives, highlighting risks of regulatory capture and greenwashing. Building on this diagnosis, the paper advances strategic recommendations for the COP30 Action Agenda, calling for binding transparency obligations, harmonized international standards for lifecycle assessment, stricter governance of data center expansion, and meaningful public participation in AI infrastructure decisions.",
      "url": "https://arxiv.org/pdf/2601.04958v1",
      "date": "2026-01-08T14:02:51+00:00"
    },
    {
      "id": "auth_thomas_le_goff",
      "name": "Thomas Le Goff",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_sustainability_laws",
      "name": "sustainability laws",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_regulation_assess",
      "name": "regulation assess",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_regulatory_landscape",
      "name": "regulatory landscape",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_sustainability_reporting",
      "name": "sustainability reporting",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_ai_environmental",
      "name": "ai environmental",
      "group": "topic",
      "val": 10
    },
    {
      "id": "2601.04403v1",
      "name": "Balancing Usability and Compliance in AI Smart Devices: A Privacy-by-Design Audit of Google Home, Alexa, and Siri",
      "group": "paper",
      "val": 30,
      "abstract": "This paper investigates the privacy and usability of AI-enabled smart devices commonly used by youth, focusing on Google Home Mini, Amazon Alexa, and Apple Siri. While these devices provide convenience and efficiency, they also raise privacy and transparency concerns due to their always-listening design and complex data management processes. The study proposes and applies a combined framework of Heuristic Evaluation, Personal Information Protection and Electronic Documents Act (PIPEDA) Compliance Assessment, and Youth-Centered Usability Testing to assess whether these devices align with Privacy-by-Design principles and support meaningful user control. Results show that Google Home achieved the highest usability score, while Siri scored highest in regulatory compliance, indicating a trade-off between user convenience and privacy protection. Alexa demonstrated clearer task navigation but weaker transparency in data retention. Findings suggest that although youth may feel capable of managing their data, their privacy self-efficacy remains limited by technical design, complex settings, and unclear data policies. The paper concludes that enhancing transparency, embedding privacy guidance during onboarding, and improving policy alignment are critical steps toward ensuring that smart devices are both usable and compliant with privacy standards that protect young users.",
      "url": "https://arxiv.org/pdf/2601.04403v1",
      "date": "2026-01-07T21:20:58+00:00"
    },
    {
      "id": "auth_trevor_de_clark",
      "name": "Trevor De Clark",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_yulia_bobkova",
      "name": "Yulia Bobkova",
      "group": "author",
      "val": 15
    },
    {
      "id": "auth_ajay_kumar_shrestha",
      "name": "Ajay Kumar Shrestha",
      "group": "author",
      "val": 15
    },
    {
      "id": "topic_privacy_usability",
      "name": "privacy usability",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_privacy_self",
      "name": "privacy self",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_privacy_guidance",
      "name": "privacy guidance",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_compliant_privacy",
      "name": "compliant privacy",
      "group": "topic",
      "val": 10
    },
    {
      "id": "topic_privacy_standards",
      "name": "privacy standards",
      "group": "topic",
      "val": 10
    }
  ],
  "links": [
    {
      "source": "2601.04175v1",
      "target": "auth_noam_kolt",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_nicholas_caputo",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_jack_boeglin",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_cullen_o'keefe",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_rishi_bommasani",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_stephen_casper",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_mariano_florentino_cuéllar",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_noah_feldman",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_iason_gabriel",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_gillian_k_hadfield",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_lewis_hammond",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_peter_henderson",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_atoosa_kasirzadeh",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_seth_lazar",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_anka_reuel",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_kevin_l_wei",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_jonathan_zittrain",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "topic_legal_alignment",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_legal_compliance",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_exploring_legal",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_specifying_ai",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_ensuring_ai",
      "value": 2
    },
    {
      "source": "2601.04107v1",
      "target": "auth_ruiyi_guo",
      "value": 5
    },
    {
      "source": "2601.04107v1",
      "target": "auth_bodong_zhang",
      "value": 5
    },
    {
      "source": "2601.04107v1",
      "target": "topic_institutional_logics",
      "value": 2
    },
    {
      "source": "2601.04107v1",
      "target": "topic_ai_governance",
      "value": 2
    },
    {
      "source": "2601.04107v1",
      "target": "topic_governs_ai",
      "value": 2
    },
    {
      "source": "2601.04107v1",
      "target": "topic_intelligence_governance",
      "value": 2
    },
    {
      "source": "2601.04107v1",
      "target": "topic_govern_ontologically",
      "value": 2
    },
    {
      "source": "2601.04094v1",
      "target": "auth_tom_deckenbrunnen",
      "value": 5
    },
    {
      "source": "2601.04094v1",
      "target": "auth_alessio_buscemi",
      "value": 5
    },
    {
      "source": "2601.04094v1",
      "target": "auth_marco_almada",
      "value": 5
    },
    {
      "source": "2601.04094v1",
      "target": "auth_alfredo_capozucca",
      "value": 5
    },
    {
      "source": "2601.04094v1",
      "target": "auth_german_castignani",
      "value": 5
    },
    {
      "source": "2601.04094v1",
      "target": "topic_eu_ai",
      "value": 2
    },
    {
      "source": "2601.04094v1",
      "target": "topic_ai_act",
      "value": 2
    },
    {
      "source": "2601.04094v1",
      "target": "topic_enforcement_macro",
      "value": 2
    },
    {
      "source": "2601.04094v1",
      "target": "topic_govern_ai",
      "value": 2
    },
    {
      "source": "2601.04094v1",
      "target": "topic_ai_technical",
      "value": 2
    },
    {
      "source": "2601.03788v1",
      "target": "auth_anamaria_mojica_hanke",
      "value": 5
    },
    {
      "source": "2601.03788v1",
      "target": "auth_thomas_goger",
      "value": 5
    },
    {
      "source": "2601.03788v1",
      "target": "auth_svenja_wölfel",
      "value": 5
    },
    {
      "source": "2601.03788v1",
      "target": "auth_brian_valerius",
      "value": 5
    },
    {
      "source": "2601.03788v1",
      "target": "auth_steffen_herbold",
      "value": 5
    },
    {
      "source": "2601.03788v1",
      "target": "topic_offense_individuals",
      "value": 2
    },
    {
      "source": "2601.03788v1",
      "target": "topic_criminal_liability",
      "value": 2
    },
    {
      "source": "2601.03788v1",
      "target": "topic_legal_consequences",
      "value": 2
    },
    {
      "source": "2601.03788v1",
      "target": "topic_criminal_legal",
      "value": 2
    },
    {
      "source": "2601.03788v1",
      "target": "topic_legal_systems",
      "value": 2
    },
    {
      "source": "2601.03733v1",
      "target": "auth_xiaoxian_shen",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_yuhui_zhang",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_sahithi_ankireddy",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_xiaohan_wang",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_maya_varma",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_henry_guo",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_curtis_langlotz",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "auth_serena_yeung_levy",
      "value": 5
    },
    {
      "source": "2601.03733v1",
      "target": "topic_multimodal_reasoning",
      "value": 2
    },
    {
      "source": "2601.03733v1",
      "target": "topic_medical_ai",
      "value": 2
    },
    {
      "source": "2601.03733v1",
      "target": "topic_radiology_image",
      "value": 2
    },
    {
      "source": "2601.03733v1",
      "target": "topic_understanding_radiology",
      "value": 2
    },
    {
      "source": "2601.03733v1",
      "target": "topic_raddiff_multimodal",
      "value": 2
    },
    {
      "source": "2601.03709v1",
      "target": "auth_sarah_spiekermann_hoff",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_marc_langheinrich",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_johannes_hoff",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_christiane_wendehorst",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_jürgen_pfeffer",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_thomas_fuchs",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "auth_armin_grunwald",
      "value": 5
    },
    {
      "source": "2601.03709v1",
      "target": "topic_digital_world",
      "value": 2
    },
    {
      "source": "2601.03709v1",
      "target": "topic_digital_technologies",
      "value": 2
    },
    {
      "source": "2601.03709v1",
      "target": "topic_ethical_psychological",
      "value": 2
    },
    {
      "source": "2601.03709v1",
      "target": "topic_rules_digital",
      "value": 2
    },
    {
      "source": "2601.03709v1",
      "target": "topic_digital",
      "value": 2
    },
    {
      "source": "2601.03693v1",
      "target": "auth_junaid_qadir",
      "value": 5
    },
    {
      "source": "2601.03693v1",
      "target": "auth_muhammad_adil_attique",
      "value": 5
    },
    {
      "source": "2601.03693v1",
      "target": "auth_saleha_shoaib",
      "value": 5
    },
    {
      "source": "2601.03693v1",
      "target": "auth_syed_ibrahim_ghaznavi",
      "value": 5
    },
    {
      "source": "2601.03693v1",
      "target": "topic_examines_ai",
      "value": 2
    },
    {
      "source": "2601.03693v1",
      "target": "topic_coaching_chatbot",
      "value": 2
    },
    {
      "source": "2601.03693v1",
      "target": "topic_ai_technical",
      "value": 2
    },
    {
      "source": "2601.03693v1",
      "target": "topic_intellectual",
      "value": 2
    },
    {
      "source": "2601.03693v1",
      "target": "topic_ai_chatbots",
      "value": 2
    },
    {
      "source": "2601.03547v1",
      "target": "auth_kunpeng_wang",
      "value": 5
    },
    {
      "source": "2601.03547v1",
      "target": "auth_jiahui_hu",
      "value": 5
    },
    {
      "source": "2601.03547v1",
      "target": "topic_ai_china",
      "value": 2
    },
    {
      "source": "2601.03547v1",
      "target": "topic_ai_capital",
      "value": 2
    },
    {
      "source": "2601.03547v1",
      "target": "topic_china_economy",
      "value": 2
    },
    {
      "source": "2601.03547v1",
      "target": "topic_growth_ai",
      "value": 2
    },
    {
      "source": "2601.03547v1",
      "target": "topic_capital_equilibrium",
      "value": 2
    },
    {
      "source": "2601.03469v1",
      "target": "auth_nadav_kunievsky",
      "value": 5
    },
    {
      "source": "2601.03469v1",
      "target": "auth_pedro_pertusi",
      "value": 5
    },
    {
      "source": "2601.03469v1",
      "target": "topic_essay_variation",
      "value": 2
    },
    {
      "source": "2601.03469v1",
      "target": "topic_essay_rewrites",
      "value": 2
    },
    {
      "source": "2601.03469v1",
      "target": "topic_persuasive_essays",
      "value": 2
    },
    {
      "source": "2601.03469v1",
      "target": "topic_writing_scores",
      "value": 2
    },
    {
      "source": "2601.03469v1",
      "target": "topic_essay_content",
      "value": 2
    },
    {
      "source": "2601.03458v1",
      "target": "auth_aron_gohr",
      "value": 5
    },
    {
      "source": "2601.03458v1",
      "target": "auth_marie_amelie_lawn",
      "value": 5
    },
    {
      "source": "2601.03458v1",
      "target": "auth_kevin_gao",
      "value": 5
    },
    {
      "source": "2601.03458v1",
      "target": "auth_inigo_serjeant",
      "value": 5
    },
    {
      "source": "2601.03458v1",
      "target": "auth_stephen_heslip",
      "value": 5
    },
    {
      "source": "2601.03458v1",
      "target": "topic_tutoring_systems",
      "value": 2
    },
    {
      "source": "2601.03458v1",
      "target": "topic_intelligent_tutoring",
      "value": 2
    },
    {
      "source": "2601.03458v1",
      "target": "topic_tutoring",
      "value": 2
    },
    {
      "source": "2601.03458v1",
      "target": "topic_homework_platform",
      "value": 2
    },
    {
      "source": "2601.03458v1",
      "target": "topic_editable_programming",
      "value": 2
    },
    {
      "source": "2601.03430v1",
      "target": "auth_mohamed_ouf",
      "value": 5
    },
    {
      "source": "2601.03430v1",
      "target": "auth_shayan_noei",
      "value": 5
    },
    {
      "source": "2601.03430v1",
      "target": "auth_zeph_van_iterson",
      "value": 5
    },
    {
      "source": "2601.03430v1",
      "target": "auth_mariam_guizani",
      "value": 5
    },
    {
      "source": "2601.03430v1",
      "target": "auth_ying_zou",
      "value": 5
    },
    {
      "source": "2601.03430v1",
      "target": "topic_contributors_oss4sg",
      "value": 2
    },
    {
      "source": "2601.03430v1",
      "target": "topic_contributors_code",
      "value": 2
    },
    {
      "source": "2601.03430v1",
      "target": "topic_github",
      "value": 2
    },
    {
      "source": "2601.03430v1",
      "target": "topic_oss_communities",
      "value": 2
    },
    {
      "source": "2601.03430v1",
      "target": "topic_oss_projects",
      "value": 2
    },
    {
      "source": "2601.03222v1",
      "target": "auth_jacob_erickson",
      "value": 5
    },
    {
      "source": "2601.03222v1",
      "target": "topic_trust_ai",
      "value": 2
    },
    {
      "source": "2601.03222v1",
      "target": "topic_autonomy_trust",
      "value": 2
    },
    {
      "source": "2601.03222v1",
      "target": "topic_conversational_ai",
      "value": 2
    },
    {
      "source": "2601.03222v1",
      "target": "topic_ai_agents",
      "value": 2
    },
    {
      "source": "2601.03222v1",
      "target": "topic_focusing_trust",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "auth_noam_kolt",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_nicholas_caputo",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_jack_boeglin",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_cullen_o'keefe",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_rishi_bommasani",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_stephen_casper",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_mariano_florentino_cuéllar",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_noah_feldman",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_iason_gabriel",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_gillian_k_hadfield",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_lewis_hammond",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_peter_henderson",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_atoosa_kasirzadeh",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_seth_lazar",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_anka_reuel",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_kevin_l_wei",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "auth_jonathan_zittrain",
      "value": 5
    },
    {
      "source": "2601.04175v1",
      "target": "topic_legal_alignment",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_legal_compliance",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_exploring_legal",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_specifying_ai",
      "value": 2
    },
    {
      "source": "2601.04175v1",
      "target": "topic_ensuring_ai",
      "value": 2
    },
    {
      "source": "2601.05232v1",
      "target": "auth_p_gilda",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_p_dungarwal",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_a_thongkham",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_e_t_ajayi",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_s_choudhary",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_t_m_terol",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_c_lam",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_j_p_araujo",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_m_mcfadyen_mungalln",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_l_s_liebovitch",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_p_t_coleman",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_h_west",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_k_sieck",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "auth_s_carter",
      "value": 5
    },
    {
      "source": "2601.05232v1",
      "target": "topic_news_social",
      "value": 2
    },
    {
      "source": "2601.05232v1",
      "target": "topic_social_media",
      "value": 2
    },
    {
      "source": "2601.05232v1",
      "target": "topic_news_dataset",
      "value": 2
    },
    {
      "source": "2601.05232v1",
      "target": "topic_videos_social",
      "value": 2
    },
    {
      "source": "2601.05232v1",
      "target": "topic_media_youtube",
      "value": 2
    },
    {
      "source": "2601.04958v1",
      "target": "auth_thomas_le_goff",
      "value": 5
    },
    {
      "source": "2601.04958v1",
      "target": "topic_sustainability_laws",
      "value": 2
    },
    {
      "source": "2601.04958v1",
      "target": "topic_regulation_assess",
      "value": 2
    },
    {
      "source": "2601.04958v1",
      "target": "topic_regulatory_landscape",
      "value": 2
    },
    {
      "source": "2601.04958v1",
      "target": "topic_sustainability_reporting",
      "value": 2
    },
    {
      "source": "2601.04958v1",
      "target": "topic_ai_environmental",
      "value": 2
    },
    {
      "source": "2601.04403v1",
      "target": "auth_trevor_de_clark",
      "value": 5
    },
    {
      "source": "2601.04403v1",
      "target": "auth_yulia_bobkova",
      "value": 5
    },
    {
      "source": "2601.04403v1",
      "target": "auth_ajay_kumar_shrestha",
      "value": 5
    },
    {
      "source": "2601.04403v1",
      "target": "topic_privacy_usability",
      "value": 2
    },
    {
      "source": "2601.04403v1",
      "target": "topic_privacy_self",
      "value": 2
    },
    {
      "source": "2601.04403v1",
      "target": "topic_privacy_guidance",
      "value": 2
    },
    {
      "source": "2601.04403v1",
      "target": "topic_compliant_privacy",
      "value": 2
    },
    {
      "source": "2601.04403v1",
      "target": "topic_privacy_standards",
      "value": 2
    }
  ]
}